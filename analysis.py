# -*- coding: utf-8 -*-
"""
The analysis module provides the function to analyse the data generated by
pyDentate. Data files generated by pyDentate have the .pydd extension.
This extension simply allows to identify files that contain the raw data
as opposed to files that contain for example plots. All data files are python
shelves and shelving is handled by ouropy.

Functions
---------


@author: daniel
"""

import numpy as np
from scipy.signal import correlate2d, convolve2d
from burst_generator_inhomogeneous_poisson import inhom_poiss
import shelve
import matplotlib.pyplot as plt

def sim_score(signal1, signal2, kernel_delta):
    """Calculate the similatiry score as in Yim et al. 2015
    
    Parameters
    ----------
    signal1, signal2 - numpy arrays
        the two signals to be correlated
    kernal_delta - numeric
        the size of the triangular kernel in datapoints

    Returns
    -------
    corr - correlation coefficient
    """
    kernel = np.append(np.arange(kernel_delta),np.arange(kernel_delta,-1,-1))
    if np.shape(signal1) == np.shape(signal2):
        kernel=np.repeat(kernel[np.newaxis,:], repeats=np.shape(signal1)[0], axis=0)
    else:
        raise ValueError("signal1 and signal2 must have same shape")
    signal1_conv = convolve2d(signal1,kernel,'same')
    signal2_conv = convolve2d(signal2,kernel,'same')
    return signal1_conv

def time_stamps_to_signal(time_stamps, dt_signal, t_start, t_stop):
    """Convert an array of timestamps to a signal where 0 is absence and 1 is
    presence of spikes
    
    Parameters
    ----------
    time_stamps - numpy array
        the time stamps array to convert
    dt_signal - numeric
        the size of the triangular kernel in datapoints, units must be
        consistent with time_stamps
    t_start - numeric
        time where the signal starts, units must be consistent with time_stamps        
    t_stop - numeric
        time where the signal stops, units must be consistent with time_stamps

    Returns
    -------
    sig - correlation coefficient
    """
    # Construct a zero array with size corresponding to desired output signal
    sig = np.zeros((np.shape(time_stamps)[0],int((t_stop-t_start)/dt_signal)))
    
    # Find the indices where spikes occured according to time_stamps
    time_idc = (time_stamps - t_start) / dt_signal
    
    # Set the spike indices to 1
    for sig_idx, idc in enumerate(time_idc):
        sig[sig_idx,np.array(idc,dtype=np.int)] = 1

    return sig

if __name__ == '__main__':
    temporal_patterns = inhom_poiss()
    time_sig = time_stamps_to_signal(temporal_patterns,
                                     dt_signal=0.1,
                                     t_start=0,
                                     t_stop=1000)

#Home PC
#directory = "C:\\Users\\daniel\\repos\\pyDentate\paradigm_pattern-separation_saves_2018-03-11\\"
#Office PC
directory = "C:\\Users\\DanielM\\Repos\\pyDentate\\paradigm_pattern-separation_saves_2018-05-02_patterns\\"
file_name = "net_tuned.TunedNetwork_run_0"

shelve_files = []
active_cells = []
for run in range(1):
    shelve_files.append(shelve.open(directory + file_name + str(run)))
    ap_n_array = np.array(shelve_files[run]['net_tuned.TunedNetwork']['populations'][0]['ap_number'])
    active_cells.append(len(np.argwhere(ap_n_array)))

# Percent Active Cells
for x in shelve_files:
    n_active_array = np.array(x['net_tuned.TunedNetwork']['populations'][0]['ap_number'])
    n_active = len(np.argwhere(n_active_array))
    perc_active = (n_active / 2000.0) * 100
    print(perc_active)